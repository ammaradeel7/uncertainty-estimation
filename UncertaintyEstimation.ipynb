{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UncertaintyEstimation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dBlVgXavxV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from IPython import display\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataset import Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP4Ni-1MwHXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVJQpQ-FxTUJ",
        "colab_type": "code",
        "outputId": "3fab1df8-691e-48c7-eda3-72f9b9911a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install pyro-ppl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.17.4)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.3.1)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (3.1.0)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (4.41.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0P26k89xZU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyro "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uS1ypl4wPTs",
        "colab_type": "code",
        "outputId": "7240e304-d95d-4ffa-ccf3-d3c7e40619a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "from scipy.misc import imread"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fdea29e23da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'imread'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hutp16e_kUj2",
        "colab_type": "text"
      },
      "source": [
        "After importing PyTorch, Pyro and other standard libraries (like matplotlib and numpy), we define a standard feedforward neural network of one hidden layer of 1024 units. We also load MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxGvrf3AwuH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 1024)\n",
        "        self.fc3 = nn.Linear(1024, 10)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.log_softmax(self.fc3(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7GmDzv_ykJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m1 = Classifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L9ugsT1xN78",
        "colab_type": "code",
        "outputId": "87f77941-03c8-4ca8-82ec-1cb0d65b1962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=True, download=True,\n",
        "                       transform=transforms.Compose([transforms.ToTensor(),])),\n",
        "        batch_size=128, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=False, transform=transforms.Compose([transforms.ToTensor(),])\n",
        "                       ),\n",
        "        batch_size=1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist-data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8297011.05it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist-data/MNIST/raw/train-images-idx3-ubyte.gz to mnist-data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist-data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 121763.27it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist-data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist-data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist-data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2011084.57it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist-data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist-data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist-data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 46755.96it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist-data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist-data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLDBOWDdksYq",
        "colab_type": "text"
      },
      "source": [
        "In Pyro, the model() function defines how the output data is generated. Within model(), the function pyro.random_module() converts parameters of our neural network (weights and biases) into random variables that have the initial (prior) probability distribution given by fc1w_prior, fc1b_prior, outw_prior and outb_prior. Finally, through pyro.sample(), we tell Pyro that the output of this network is categorical in nature (i.e. it can either be 0, 1, 2, and so on.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_8iKJCVxRa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyro.distributions import Normal, Categorical\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "\n",
        "log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "\n",
        "def model(x_data, y_data):\n",
        "    \n",
        "    fc1w_prior = Normal(loc=torch.zeros_like(m1.fc1.weight), scale=torch.ones_like(m1.fc1.weight))\n",
        "    fc1b_prior = Normal(loc=torch.zeros_like(m1.fc1.bias), scale=torch.ones_like(m1.fc1.bias))\n",
        "    \n",
        "    \n",
        "\n",
        "    outw_prior = Normal(loc=torch.zeros_like(m1.fc3.weight), scale=torch.ones_like(m1.fc3.weight))\n",
        "    outb_prior = Normal(loc=torch.zeros_like(m1.fc3.bias), scale=torch.ones_like(m1.fc3.bias))\n",
        "\n",
        "    \n",
        "    priors = {'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior, 'out.weight': outw_prior, 'out.bias': outb_prior}\n",
        "    # lift module parameters to random variables sampled from the priors\n",
        "    lifted_module = pyro.random_module(\"module\", m1, priors)\n",
        "    # sample a regressor (which also samples w and b)\n",
        "    lifted_reg_model = lifted_module()\n",
        "    \n",
        "    lhat = log_softmax(lifted_reg_model(x_data))\n",
        "    \n",
        "    pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmYYMdlK_QNQ",
        "colab_type": "text"
      },
      "source": [
        "The guide function helps us initialize a well-behaved distribution that later we can optimize to approximate the true posterior. This guide() function describes the Z parameters (like mean and variance of weights and biases) that can be changed to see if resultant distribution closely approximates the posterior that comes out of model(). Now, in our case the model() looks very similar to guide() but that need not always be the case. In theory, the model() function could be much more complicated than the guide() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_66yfg5-zV_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "softplus = torch.nn.Softplus()\n",
        "\n",
        "def guide(x_data, y_data):\n",
        "    \n",
        "    # First layer weight distribution priors\n",
        "    fc1w_mu = torch.randn_like(m1.fc1.weight)\n",
        "    fc1w_sigma = torch.randn_like(m1.fc1.weight)\n",
        "    fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu)\n",
        "    fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma))\n",
        "    fc1w_prior = Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param)\n",
        "    # First layer bias distribution priors\n",
        "    fc1b_mu = torch.randn_like(m1.fc1.bias)\n",
        "    fc1b_sigma = torch.randn_like(m1.fc1.bias)\n",
        "    fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu)\n",
        "    fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma))\n",
        "    fc1b_prior = Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param)\n",
        " \n",
        "    # Output layer weight distribution priors\n",
        "    outw_mu = torch.randn_like(m1.fc3.weight)\n",
        "    outw_sigma = torch.randn_like(m1.fc3.weight)\n",
        "    outw_mu_param = pyro.param(\"outw_mu\", outw_mu)\n",
        "    outw_sigma_param = softplus(pyro.param(\"outw_sigma\", outw_sigma))\n",
        "    outw_prior = Normal(loc=outw_mu_param, scale=outw_sigma_param).independent(1)\n",
        "    # Output layer bias distribution priors\n",
        "    outb_mu = torch.randn_like(m1.fc3.bias)\n",
        "    outb_sigma = torch.randn_like(m1.fc3.bias)\n",
        "    outb_mu_param = pyro.param(\"outb_mu\", outb_mu)\n",
        "    outb_sigma_param = softplus(pyro.param(\"outb_sigma\", outb_sigma))\n",
        "    outb_prior = Normal(loc=outb_mu_param, scale=outb_sigma_param)\n",
        "    priors = {'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior,'out.weight': outw_prior, 'out.bias': outb_prior}\n",
        "    \n",
        "    lifted_module = pyro.random_module(\"module\",m1, priors)\n",
        "    \n",
        "    return lifted_module()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP7rFPyO_vTx",
        "colab_type": "text"
      },
      "source": [
        "We’re using the Adam optimizer from PyTorch. The loss function that we’re using for optimization is ELBO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcy-u8nm0x-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim = Adam({\"lr\": 0.01})\n",
        "svi = SVI(model, guide, optim, loss=Trace_ELBO())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkfNgSNnABt1",
        "colab_type": "text"
      },
      "source": [
        "Let’s write the optimization loop. This loop is pretty much how we train a standard neural network. There are multiple epochs / iterations (in this case it’s 5). And in each iteration, we go through a mini-batch of data. One more benefit of variational inference is that we do not have to feed in the entire dataset in one go (which could be in millions). Since an optimizer takes many thousands of steps to find the best value of parameters of guide function, at each step we can feed it the a separate mini-batch of data. This speeds up inference tremendously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTAiAUzg03cG",
        "colab_type": "code",
        "outputId": "ac35412c-d139-49ef-a29a-d0d18b5891ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "\n",
        "num_iterations = 5\n",
        "loss = 0\n",
        "\n",
        "for j in range(num_iterations):\n",
        "    loss = 0\n",
        "    for batch_id, data in enumerate(train_loader):\n",
        "        # calculate the loss and take a gradient step\n",
        "        loss += svi.step(data[0].view(-1,28*28), data[1])\n",
        "    normalizer_train = len(train_loader.dataset)\n",
        "    total_epoch_loss_train = loss / normalizer_train\n",
        "    \n",
        "    print(\"Epoch \", j, \" Loss \", total_epoch_loss_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:368: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  0  Loss  1046.1424515630085\n",
            "Epoch  1  Loss  48.10283396708171\n",
            "Epoch  2  Loss  43.565052978515624\n",
            "Epoch  3  Loss  44.07243964335124\n",
            "Epoch  4  Loss  44.5184076171875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7HMHslVAz2v",
        "colab_type": "text"
      },
      "source": [
        "We’re using the learned guide() function to do predictions. This is because for model(), all we know is priors for weights and not the posterior. But for guide() after optimization iterations, the distribution given by the parameter values approximate the true posterior and so we can use it for predictions. Second thing to notice is that for each prediction, we’re sampling a new set of weights and parameters 10 times (given by num_samples)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXhF1Q9SScFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=False, transform=transforms.Compose([transforms.ToTensor(),])\n",
        "                       ),\n",
        "        batch_size=1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jOmMOkDhPTr",
        "colab_type": "code",
        "outputId": "61b9046f-fb2c-4c82-c6b8-a664c6b53621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "pip install torch-helpers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-helpers\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/56/43063fe9d0c2f7263d6ac81a96a8328daf36b6a2e20ba3cdf3841c3e01d9/torch_helpers-0.4.6-py3-none-any.whl\n",
            "Collecting moleskin\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/f9/d92633b74ec845b62c97a989ec6e4f2f29da059c8a3830920d789abe5dfc/moleskin-1.5.1-py3-none-any.whl\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from moleskin->torch-helpers) (1.1.0)\n",
            "Collecting pprint\n",
            "  Downloading https://files.pythonhosted.org/packages/99/12/b6383259ef85c2b942ab9135f322c0dce83fdca8600d87122d2b0181451f/pprint-0.1.tar.gz\n",
            "Collecting boltons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/b2/2893b608ff69fea56d3c4993bfe88bcfdd4c33d32f6a476eed09ca9d9191/boltons-19.3.0-py2.py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 8.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pprint\n",
            "  Building wheel for pprint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pprint: filename=pprint-0.1-cp36-none-any.whl size=1250 sha256=7b2860275c487f27a34d80206b7d5a3c2fa731da9a04ef2dd4f370abbc2b4341\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/d4/c6/16a6495aecc1bda5d5857bd036efd50617789ba9bea4a05124\n",
            "Successfully built pprint\n",
            "Installing collected packages: pprint, boltons, moleskin, torch-helpers\n",
            "Successfully installed boltons-19.3.0 moleskin-1.5.1 pprint-0.1 torch-helpers-0.4.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0XeJyZNjbiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Entropy(x):\n",
        "  s =(F.softmax(x, dim=1) * F.log_softmax(x, dim=1))\n",
        "  s = -1.0 * s.sum()\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpgHrQhP2UCA",
        "colab_type": "code",
        "outputId": "7dec3e37-dc9c-4ee6-be78-e519d3a2916e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "\n",
        "num_samples = 100\n",
        "def predict(x):\n",
        "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
        "    average = [model(x).data for model in sampled_models]\n",
        "    ensemble = [guide(None, None) for _ in range(3)]\n",
        "    yhats = [model(x).data for model in ensemble]\n",
        "    #print(yhats)\n",
        "    mean = torch.mean(torch.stack(average), 0)\n",
        "    #print(mean)\n",
        "    #print(F.softmax(mean))\n",
        "    #print(F.log_softmax(yhats[0]))\n",
        "    #print(F.log_softmax(yhats[1]))\n",
        "    #print(F.log_softmax(yhats[2]))\n",
        "    entropyPosterior = Entropy(mean)\n",
        "    avgEntropy = (Entropy(yhats[0]) + Entropy(yhats[1]) + Entropy(yhats[2]))/3 \n",
        "    #print(entropyPosterior)\n",
        "    #print(avgEntropy)\n",
        "    diff = entropyPosterior-avgEntropy\n",
        "\n",
        "    #print(entropyPosterior)\n",
        "    #print(avgEntropy)\n",
        "\n",
        "\n",
        "    if diff < 0:\n",
        "      diff *=-1\n",
        "\n",
        "      print(diff)\n",
        "\n",
        "\n",
        "    if diff >= 0.1:\n",
        "      print(\"uncertain\")\n",
        "\n",
        "    return torch.argmax(mean, dim=1)\n",
        "\n",
        "print('Prediction when network is forced to predict')\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images, labels = data\n",
        "images=images[0]\n",
        "labels=labels[0]\n",
        "\n",
        "predicted = predict(images.view(-1,28*28))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction when network is forced to predict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:368: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1770)\n",
            "tensor(0.1770)\n",
            "uncertain\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ookmzc2O3Wwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_batch(images, labels, plot=True):\n",
        "    y = give_uncertainities(images)\n",
        "    predicted_for_images = 0\n",
        "    correct_predictions=0\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "    \n",
        "        if(plot):\n",
        "            print(\"Real: \",labels[i].item())\n",
        "            fig, axs = plt.subplots(1, 10, sharey=True,figsize=(20,2))\n",
        "    \n",
        "        all_digits_prob = []\n",
        "    \n",
        "        highted_something = False\n",
        "    \n",
        "        for j in range(len(classes)):\n",
        "        \n",
        "            highlight=False\n",
        "        \n",
        "            histo = []\n",
        "            histo_exp = []\n",
        "        \n",
        "            for z in range(y.shape[0]):\n",
        "                histo.append(y[z][i][j])\n",
        "                histo_exp.append(np.exp(y[z][i][j]))\n",
        "            \n",
        "            prob = np.percentile(histo_exp, 50) #sampling median probability\n",
        "        \n",
        "            if(prob>0.2): #select if network thinks this sample is 20% chance of this being a label\n",
        "                highlight = True #possibly an answer\n",
        "        \n",
        "            all_digits_prob.append(prob)\n",
        "            \n",
        "            if(plot):\n",
        "            \n",
        "                N, bins, patches = axs[j].hist(histo, bins=8, color = \"lightgray\", lw=0,  weights=np.ones(len(histo)) / len(histo), density=False)\n",
        "                axs[j].set_title(str(j)+\" (\"+str(round(prob,2))+\")\") \n",
        "        \n",
        "            if(highlight):\n",
        "            \n",
        "                highted_something = True\n",
        "                \n",
        "                if(plot):\n",
        "\n",
        "                    # We'll color code by height, but you could use any scalar\n",
        "                    fracs = N / N.max()\n",
        "\n",
        "                    # we need to normalize the data to 0..1 for the full range of the colormap\n",
        "                    norm = colors.Normalize(fracs.min(), fracs.max())\n",
        "\n",
        "                    # Now, we'll loop through our objects and set the color of each accordingly\n",
        "                    for thisfrac, thispatch in zip(fracs, patches):\n",
        "                        color = plt.cm.viridis(norm(thisfrac))\n",
        "                        thispatch.set_facecolor(color)\n",
        "\n",
        "    \n",
        "        if(plot):\n",
        "            plt.show()\n",
        "    \n",
        "        predicted = np.argmax(all_digits_prob)\n",
        "    \n",
        "        if(highted_something):\n",
        "            predicted_for_images+=1\n",
        "            if(labels[i].item()==predicted):\n",
        "                if(plot):\n",
        "                    print(\"Correct\")\n",
        "                correct_predictions +=1.0\n",
        "            else:\n",
        "                if(plot):\n",
        "                    print(\"Incorrect :()\")\n",
        "        else:\n",
        "            if(plot):\n",
        "                print(\"Undecided.\")\n",
        "        \n",
        "        if(plot):\n",
        "            imshow(images[i].squeeze())\n",
        "        \n",
        "    \n",
        "    if(plot):\n",
        "        print(\"Summary\")\n",
        "        print(\"Total images: \",len(labels))\n",
        "        print(\"Predicted for: \",predicted_for_images)\n",
        "        print(\"Accuracy when predicted: \",correct_predictions/predicted_for_images)\n",
        "        \n",
        "    return len(labels), correct_predictions, predicted_for_images"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}